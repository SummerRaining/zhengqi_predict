### 今日完成
1. 阅读 https://tianchi.aliyun.com/notebook-ai/detail?spm=5176.12586969.1002.21.3f9274ffv58xbx&postId=41563 
2. "展示所有特征在训练集和测试集上的特征分布，然后删除分布不一致的特征。"查看这个操作的作用，使用extra_tree，固定超参数，查看测试集和线上得分。
	1. 读取数据，训练集和测试集合并在一起，然后对所有特征绘制分布图像。删除差异大的特征，然后重新分割训练集和测试集。训练集中分割出验证集。导出配置模型，重新交叉验证训练。
	2. extra_tree对未处理后前，使用最优的参数。五折交叉验证得分：0.1265, 验证集的得分：0.1106，线上得分：0.1299。
	3. 处理后，依然使用上次的最优参数。五折交叉验证得分：0.1276,验证集的得分：0.1105，线上得分：0.1308。
	4. 结论：结果没有更好，反而变的更差了，这是为什么？可能是因为使用以前的超参数不合理？或者由于extra_tree线上评分和线下差距不大，所以删除分布不同的特征没有影响。
3. 为了弄清楚原因,是否是extra_tree的泛化性太好导致该操作无效。我们使用rf，gbdt，xgboost，lightgbm做实验。
	- seleted_extra_tree5折交叉验证的结果为-0.1279，seleted_extra_tree验证集上的均方误差为0.1107，线上得分：0.1308。
	- seleted_rf5折交叉验证的结果为-0.1294，seleted_rf验证集上的均方误差为0.1151，线上得分：0.1396。
	- seleted_gbdt5折交叉验证的结果为-0.1147，seleted_gbdt验证集上的均方误差为0.1008，线上得分：0.1481。
	- seleted_xgboost5折交叉验证的结果为-0.1197，seleted_xgboost验证集上的均方误差为0.1085，线上得分：0.1544。
	- 结论：与训练器没有关系，整体的线上得分并没有提高，反而略微下降了。


4. 以前使用的超参数不合理，将超参数集体更改后尝试。 
	- 也不正确，这个过程中。我发现很多模型的超参数值是比较合理的，无需再更改。
	- 删除完特征后，超参数值是否发生了改变？分析，变化应该不大。
5. 这些参数是否为无用参数，加入模型并不影响结果，所以模型训练时将其权重置为0了？
	- 通过xgboost打印特征的重要程度，发现其中最大的权重是0.8246%，比较有效。需要保留，从结果来看保留特征的模型结果略微优秀一些。
6. 结论：删除与测试集上不一样分布的特征，并不能提升模型的性能。
### 今日总结
1. 今天分析了删除特征并不能提高线上得分，也不能使线下得分与线上得分差距减少。反而会有所削弱模型效果。对不同的分类器做在删除特征前后做了实验。
2. 超参数的选择对模型的影响很大，后期需要更精细地调整超参数。
3. 总结每个操作是否能对模型产生影响，太耗时间。改变策略，先运行别人已有的优秀方案，再总结其中可能有用的操作。进行实验。

### 明日计划
1. 运行线上0.095的代码，在本地spyder上，查看是否能达到0.095。
2. 总结其中可能有效的操作。从最优方案出发，减少该操作是否会对模型产生影响。
3. 将常规操作写入类中，方便以后调用。



