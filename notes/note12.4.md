1. 总结作者的实验和结果。
	SVR 得分: 0.1272 (0.0234)
	Linear 得分: 0.1293 (0.0222)
	Lasso 得分: 0.1289 (0.0225)
	ElasticNet 得分: 0.1290 (0.0225)
	Kernel Ridge2 得分: 0.1273 (0.0218)
	Kernel Ridge1 得分: 0.1372 (0.0271)
	NN 得分: 0.1425 (0.0327)
	Xgboost 得分: 0.1320 (0.0270)
	LGBM 得分: 0.1356 (0.0276)
	对基模型svr,KRR2,lgbm,nn集成后的得分: 0.1250 (0.0228)，线上得分0.1142。
2. 分析结果：以上是5折交叉验证的结果，预测用的模型使用整个数据集所以得分会更高。
	1. 模型几乎没有过拟合，线上和线下的结果保持一致。思考为什么？模型的泛化能力这么好！
	2. 为什么使用svr,krr2,lgbm,nn做集成。得分最高的四个模型应该是svr,krr2,lasso,linear reg。为什么使用

3. 了解作者所使用的模型。<完成！>
4. 从后往前尝试，是否是集成操作提升了模型的性能。将svr(线性核),krr2(线性核),lgbm,nn单独预测后提交。
	1. 实验1不使用集成模型，各个单模型结果：
		1. Kernel Ridge2 得分: 0.1273 (0.0218)，线上得分：0.1179
		2. LGBM 得分: 0.1356 (0.0276)，线上得分:0.1374
		3. SVR 得分: 0.1272 (0.0234), 线上得分:0.1182
		4. NN 得分: 0.1425 (0.0327), 线上得分:0.1191
		5. Xgboost 得分: 0.1335 (0.0294)，线上得分:0.1430
	2. 模型结论：集成多个模型并没有带来结果上面的提升。集成的结果与krr2,svr,NN的结果差不多。
	3. lgbm并未调参，但是依然比我之前调参后的结果更好。说明数据处理对模型的有很大的提升，且同样的数据处理对不同模型的提升程度是不一样的。
	4. 在这里对lgbm提升较小，但是对线性核的svr，krr2,nn提升很大。猜测这些都比较擅长捕捉线性关系，而偏态处理将数据展现了线性性。
	5. 以后只使用krr2和lgbm模型检验操作的有效性。

5. 单变量选择，了解原理SelectKBest，对比实验查看去掉该操作后是否减弱模型。<完成！>
	1. 每个自变量和标签之间做一个F统计量的相关性分析。计算特征x与标签之间的相关系数，然后检验相关系数的显著性。使用F统计量。https://zhuanlan.zhihu.com/p/36441826。
	2. 移除单变量选择后实验2：
		1. Kernel Ridge2 得分: 0.1274 (0.0241)，线上得分：0.1237
		2. LGBM 得分: 0.1366 (0.0279)，线上得分：0.1348
		3. SVR 得分: 0.1289 (0.0242)，线上得分：0.1225
		4. NN 得分: 0.1654 (0.0265)，线上得分：0.1496
		5. Xgboost 得分: 0.1330 (0.0288),线上得分:0.1347
	3. 线下得分虽然几乎未变，但是对于krr2来说线上得分有了很大的提升(0.06)，svr线上得分提升(0.04)，(全线性神经网络)NN得分线上线下提升都很大，而且模型方差减小了。
	4. 说明单变量特征选择对于一些模型可以提高泛化能力，减少过拟合。对分布不一致的数据集有作用。
	5. __猜测可能对树形模型无用，lgbm和xgboost特征越多，效果越好，线上线下效果都有增强。单变量选择对其无用！__

6. 方差选择，对比查看去掉该操作是否减弱模型。
	1. 这个选择方式与单变量选择操作可能重复了，应该是对线性的模型有效，而对树形模型无用。单变量选择可能也能去除掉这部分变量，所以所有的模型结果都不会有变化。
	2. 移除方差选择，但是依然做单变量选择后的实验3，也就是这里只使用18个经过__单变量方法选择出来的__变量：
		1. SVR 得分: 0.1211 (0.0223)，线上得分：1.6687
		2. Kernel Ridge2 得分: 0.1275 (0.0202)，线上得分：0.1825
		3. LGBM 得分: 0.1358 (0.0291)，线上得分：0.1363
		4. NN 得分: 0.1376 (0.0319)，线上得分：0.2137
		5. Xgboost 得分: 0.1324 (0.0299)，线上得分：0.1420
	3. 方差选择对线性模型(SVR,全线性NN,KRR2)的影响__非常巨大！__，对于树型模型虽然也有影响但相对而言并不大。
	4. 这里树形结构模型效果变差可能是由于，使用单变量筛选后只剩18个特征，相比以前的18个特征，现在的更差了。如果使用全特征，模型会变差嘛？
	5. 实验3.1不使用单变量和方差选择的特征筛选，训练树形模型：
		1. LGBM 得分: 0.1359 (0.0283),线上得分:0.1327。
		2. Xgboost 得分: 0.1331 (0.0289),线上得分:0.1358。
	6. 结果对比，方差选择和单变量选择筛选特征。lgbm,xgboost筛选前(0.1327，0.1358)，筛选后(0.1374,0.1430)。
	7. __方差选择对线性模型十分重要__，每次实验前建议都使用__方差选择配合单变量选择使用__。对于树形模型，不使用__这两种方法筛选特征更好一些__。看来树形结构有自己筛选变量的特点。
7. 偏态纠正操作，查看去掉该操作后是否减弱模型，如果有用了解原理。
8. 标准化操作，与偏态操作同时进行。

9. 对部分模型调参，后融合提交。
10. 增加交叉项特征后训练提交。

今日总结：
1. 针对模型平均融合，单变量筛选，方差筛选做实验。
2. 对于我们这个问题模型融合没有效果。
3. __重要__单变量筛选和方差筛选配合使用对__线性模型(SVR,KRR2,NN)非常重要！__，主要表现在增强模型的泛化能力，减小线上线下的差异。
	- 筛选前(SVR,KRR2,NN)的结果0.1211(1.6687),0.1275(0.1825),0.1376(0.2137)，括号中是线上
	- 筛选后(SVR,KRR2,NN)的结果0.1289(0.1225),0.1274(0.1179),0.1425(0.1191)，括号中是线上
	- 观察发现，筛选特征后交叉验证结果反而变差，但是线上的结果大大增强。(注：筛选时使用的线下特征，并未使用线上特征)
4. 单变量筛选和方差的使用对__树形结构的模型(LGBM,Xgboost)无效反而有损害__。猜测树形结构有自己筛选变量的特点。

明日计划：
0. 树形模型的默认参数，max\_depth,learning\_rate,n\_estimators,subsample。和调整好的参数，上传到github。
1. 偏态纠正操作，查看去掉该操作后是否减弱模型，如果有用了解原理。
2. 标准化操作，与偏态操作同时进行。
3. 对部分模型调参，后融合提交。
4. 增加交叉项特征后训练提交。

