### 明日计划
1. 运行线上0.095的代码，在本地jupyter上，查看是否能达到0.095。<完成！>
	1. 提交了将模型取平均后的模型结果，0.1288。
	2. 这份代码无效，不能得到好结果。
2. 运行0.1119的代码 https://tianchi.aliyun.com/notebook-ai/home#notebookLabId=71953&notebookType=PRIVATE&isHelp=false&operaType=5 <完成!>
	1. 得到结果0.117，与原文描述一致。
3. 放入spyder上运行，同时总结操作，整理认为有用的操作。<完成！>
	1. 删除训练集和线上测试集分布不同的特征。
	2. 标准化，对所有的特征做0-1范围内的缩放。
	3. 偏态处理，分析所有的特征的偏度skewness统计量。E[(X-u)/sigma]^3，标准化后的三阶矩。对对分布很偏的特征做对数化或者指数化。
	4. 偏态操作后，重新标准化到0-1范围之间。	
	5. 方差选择特征，删除方差小于0.85*0.15的特征。
	6. 单变量选择，只选择最好的18个特征，训练svr，KRR2,lgbm,nn模型。
	7. 对上述四个模型做平均融合，得到预测结果。

4. 总结作者的实验和结果。
	SVR 得分: 0.1272 (0.0234)
	Line 得分: 0.1293 (0.0222)
	Lasso 得分: 0.1289 (0.0225)
	ElasticNet 得分: 0.1290 (0.0225)
	Kernel Ridge2 得分: 0.1273 (0.0218)
	Kernel Ridge1 得分: 0.1372 (0.0271)
	NN 得分: 0.1425 (0.0327)
	Xgboost 得分: 0.1320 (0.0270)
	LGBM 得分: 0.1356 (0.0276)
	对基模型svr,KRR2,lgbm,nn集成后的得分: 0.1250 (0.0228)，线上得分0.1142。
5. 分析结果：以上是5折交叉验证的结果，预测用的模型使用整个数据集所以得分会更高。
	1. 模型几乎没有过拟合，线上和线下的结果保持一致。思考为什么？模型的泛化能力这么好！
	2. 

4. 总结其中可能有效的操作。从最优方案出发，减少该操作是否会对模型产生影响。
	1. 
5. 将常规操作写入类中，方便以后调用。

